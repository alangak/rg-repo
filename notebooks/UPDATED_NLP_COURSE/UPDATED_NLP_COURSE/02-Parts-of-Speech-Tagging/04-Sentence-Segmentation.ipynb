{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.7"},"colab":{"name":"04-Sentence-Segmentation.ipynb","provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"HjaEqr9PWdTd","colab_type":"text"},"source":["___\n","\n","<a href='http://www.pieriandata.com'> <img src='../Pierian_Data_Logo.png' /></a>\n","___"]},{"cell_type":"markdown","metadata":{"id":"USv0UM44WdTh","colab_type":"text"},"source":["# Sentence Segmentation\n","In **spaCy Basics** we saw briefly how Doc objects are divided into sentences. In this section we'll learn how sentence segmentation works, and how to set our own segmentation rules."]},{"cell_type":"code","metadata":{"id":"H9pL5Y-NWdTk","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594606993223,"user_tz":-330,"elapsed":4675,"user":{"displayName":"Rahul Gulabani","photoUrl":"","userId":"12132587162706927266"}}},"source":["# Perform standard imports\n","import spacy\n","nlp = spacy.load('en_core_web_sm')"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"mUbo5alBWdTw","colab_type":"code","colab":{},"outputId":"796db934-0bb5-455d-c5d0-ed318b161941"},"source":["# From Spacy Basics:\n","doc = nlp(u'This is the first sentence. This is another sentence. This is the last sentence.')\n","\n","for sent in doc.sents:\n","    print(sent)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["This is the first sentence.\n","This is another sentence.\n","This is the last sentence.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"TypQLaN4WdT8","colab_type":"text"},"source":["### `Doc.sents` is a generator\n","It is important to note that `doc.sents` is a *generator*. That is, a Doc is not segmented until `doc.sents` is called. This means that, where you could print the second Doc token with `print(doc[1])`, you can't call the \"second Doc sentence\" with `print(doc.sents[1])`:"]},{"cell_type":"code","metadata":{"id":"h2ZPHWdjWdT-","colab_type":"code","colab":{},"outputId":"35064d11-8643-42e9-ba6d-794c816603e9"},"source":["print(doc[1])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["is\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tz-WNhffWdUI","colab_type":"code","colab":{},"outputId":"796a4562-1f1a-45c7-f132-475e6d85b048"},"source":["print(doc.sents[1])"],"execution_count":null,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"'generator' object is not subscriptable","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[1;32m<ipython-input-4-2bc012eee1da>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msents\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[1;31mTypeError\u001b[0m: 'generator' object is not subscriptable"]}]},{"cell_type":"markdown","metadata":{"id":"Vj2fgKUzWdUR","colab_type":"text"},"source":["However, you *can* build a sentence collection by running `doc.sents` and saving the result to a list:"]},{"cell_type":"code","metadata":{"id":"zsBTRiwIWdUT","colab_type":"code","colab":{},"outputId":"69cf7ee1-ac97-4f54-c9d3-7096bac60d2e"},"source":["doc_sents = [sent for sent in doc.sents]\n","doc_sents"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[This is the first sentence.,\n"," This is another sentence.,\n"," This is the last sentence.]"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"-V2Ejs6hWdUd","colab_type":"text"},"source":["<font color=green>**NOTE**: `list(doc.sents)` also works. We show a list comprehension as it allows you to pass in conditionals.</font>"]},{"cell_type":"code","metadata":{"id":"oQL-3dRbWdUf","colab_type":"code","colab":{},"outputId":"1f785f4c-fc4b-4334-91e8-12eb9c9151af"},"source":["# Now you can access individual sentences:\n","print(doc_sents[1])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["This is another sentence.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Kf0slmoNWdUq","colab_type":"text"},"source":["### `sents` are Spans\n","At first glance it looks like each `sent` contains text from the original Doc object. In fact they're just Spans with start and end token pointers."]},{"cell_type":"code","metadata":{"id":"pX3YUpYAWdUr","colab_type":"code","colab":{},"outputId":"d4c734b7-0a1e-48bd-dd7f-485d5e1ca7e9"},"source":["type(doc_sents[1])"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["spacy.tokens.span.Span"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"hBkxsyxQWdU3","colab_type":"code","colab":{},"outputId":"91425fcd-05ef-43bc-d27a-58be1f671527"},"source":["print(doc_sents[1].start, doc_sents[1].end)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["6 11\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"78thoVyrWdVC","colab_type":"text"},"source":["## Adding Rules\n","spaCy's built-in `sentencizer` relies on the dependency parse and end-of-sentence punctuation to determine segmentation rules. We can add rules of our own, but they have to be added *before* the creation of the Doc object, as that is where the parsing of segment start tokens happens:"]},{"cell_type":"code","metadata":{"id":"TwIerCPXWdVE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":290},"executionInfo":{"status":"ok","timestamp":1594607090310,"user_tz":-330,"elapsed":3283,"user":{"displayName":"Rahul Gulabani","photoUrl":"","userId":"12132587162706927266"}},"outputId":"dcf2fc54-a597-4fdc-f08b-d709f718c5fb"},"source":["# Parsing the segmentation start tokens happens during the nlp pipeline\n","doc2 = nlp(u'This is a sentence. This is a sentence. This is a sentence.')\n","\n","for token in doc2:\n","    print(token.is_sent_start, ' '+token.text)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["True  This\n","None  is\n","None  a\n","None  sentence\n","None  .\n","True  This\n","None  is\n","None  a\n","None  sentence\n","None  .\n","True  This\n","None  is\n","None  a\n","None  sentence\n","None  .\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"mEhXom1CWdVM","colab_type":"text"},"source":["<font color=green>Notice we haven't run `doc2.sents`, and yet `token.is_sent_start` was set to True on two tokens in the Doc.</font>"]},{"cell_type":"markdown","metadata":{"id":"a6za3XEgWdVO","colab_type":"text"},"source":["Let's add a semicolon to our existing segmentation rules. That is, whenever the sentencizer encounters a semicolon, the next token should start a new segment."]},{"cell_type":"code","metadata":{"id":"f1G_h9UnWdVQ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":90},"executionInfo":{"status":"ok","timestamp":1594607285142,"user_tz":-330,"elapsed":3209,"user":{"displayName":"Rahul Gulabani","photoUrl":"","userId":"12132587162706927266"}},"outputId":"c32b3ca2-3a7c-4f6f-b9e2-712d84d0890b"},"source":["# SPACY'S DEFAULT BEHAVIOR\n","doc3 = nlp(u'\"Management is doing things right; leadership is doing the right things.\" -Peter Drucker')\n","print(doc3[:-1])     #remove the last word or token\n","for sent in doc3.sents:\n","    print(sent)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["\"Management is doing things right; leadership is doing the right things.\" -Peter\n","\"Management is doing things right; leadership is doing the right things.\"\n","-Peter\n","Drucker\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GBtc_ZNrWdVY","colab_type":"code","colab":{},"outputId":"bb6efefc-72de-415c-f015-5c1eb7fe03f4"},"source":["# ADD A NEW RULE TO THE PIPELINE\n","def set_custom_boundaries(doc):\n","    for token in doc[:-1]:\n","        if token.text == ';':\n","            doc[token.i+1].is_sent_start = True\n","    return doc\n","\n","nlp.add_pipe(set_custom_boundaries, before='parser')\n","\n","nlp.pipe_names"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['tagger', 'set_custom_boundaries', 'parser', 'ner']"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"markdown","metadata":{"id":"mxMdrpSCWdVh","colab_type":"text"},"source":["<font color=green>The new rule has to run before the document is parsed. Here we can either pass the argument `before='parser'` or `first=True`."]},{"cell_type":"code","metadata":{"id":"ivb7Qr7EWdVj","colab_type":"code","colab":{},"outputId":"4073b5f7-0c17-49e2-9d64-a685072faf7f"},"source":["# Re-run the Doc object creation:\n","doc4 = nlp(u'\"Management is doing things right; leadership is doing the right things.\" -Peter Drucker')\n","\n","for sent in doc4.sents:\n","    print(sent)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\"Management is doing things right;\n","leadership is doing the right things.\"\n","-Peter Drucker\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jZ5mnM7DWdVr","colab_type":"code","colab":{},"outputId":"7faa323b-4ce8-47e4-d11e-69451184c6f1"},"source":["# And yet the new rule doesn't apply to the older Doc object:\n","for sent in doc3.sents:\n","    print(sent)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\"Management is doing things right; leadership is doing the right things.\"\n","-Peter Drucker\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"O3fKdQlBWdV0","colab_type":"text"},"source":["### Why not change the token directly?\n","Why not simply set the `.is_sent_start` value to True on existing tokens?"]},{"cell_type":"code","metadata":{"id":"2OBeEPKmWdV3","colab_type":"code","colab":{},"outputId":"ea796a23-fe66-44d7-80b6-3843f4c6c68c"},"source":["# Find the token we want to change:\n","doc3[7]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["leadership"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"YrCriKN2WdV_","colab_type":"code","colab":{},"outputId":"505b140e-d270-44ca-bda2-cef790ae2e52"},"source":["# Try to change the .is_sent_start attribute:\n","doc3[7].is_sent_start = True"],"execution_count":null,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"[E043] Refusing to write to token.sent_start if its document is parsed, because this may cause inconsistent state.","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[1;32m<ipython-input-5-bcec3fe6a9a2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Try to change the .is_sent_start attribute:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdoc3\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_sent_start\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[1;32mtoken.pyx\u001b[0m in \u001b[0;36mspacy.tokens.token.Token.is_sent_start.__set__\u001b[1;34m()\u001b[0m\n","\u001b[1;31mValueError\u001b[0m: [E043] Refusing to write to token.sent_start if its document is parsed, because this may cause inconsistent state."]}]},{"cell_type":"markdown","metadata":{"id":"PGVFHKy5WdWI","colab_type":"text"},"source":["<font color=green>spaCy refuses to change the tag after the document is parsed to prevent inconsistencies in the data.</font>"]},{"cell_type":"markdown","metadata":{"id":"ezpvdSgeWdWL","colab_type":"text"},"source":["## Changing the Rules\n","In some cases we want to *replace* spaCy's default sentencizer with our own set of rules. In this section we'll see how the default sentencizer breaks on periods. We'll then replace this behavior with a sentencizer that breaks on linebreaks."]},{"cell_type":"code","metadata":{"id":"Mm972x9TWdWN","colab_type":"code","colab":{},"outputId":"3e5bf165-4455-4176-d89e-7f7146f0463d"},"source":["nlp = spacy.load('en_core_web_sm')  # reset to the original\n","\n","mystring = u\"This is a sentence. This is another.\\n\\nThis is a \\nthird sentence.\"\n","\n","# SPACY DEFAULT BEHAVIOR:\n","doc = nlp(mystring)\n","\n","for sent in doc.sents:\n","    print([token.text for token in sent])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['This', 'is', 'a', 'sentence', '.']\n","['This', 'is', 'another', '.', '\\n\\n']\n","['This', 'is', 'a', '\\n', 'third', 'sentence', '.']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"H8ykuzd2WdWc","colab_type":"code","colab":{}},"source":["# CHANGING THE RULES\n","from spacy.pipeline import SentenceSegmenter\n","\n","def split_on_newlines(doc):\n","    start = 0\n","    seen_newline = False\n","    for word in doc:\n","        if seen_newline:\n","            yield doc[start:word.i]\n","            start = word.i\n","            seen_newline = False\n","        elif word.text.startswith('\\n'): # handles multiple occurrences\n","            seen_newline = True\n","    yield doc[start:]      # handles the last group of tokens\n","\n","\n","sbd = SentenceSegmenter(nlp.vocab, strategy=split_on_newlines)\n","nlp.add_pipe(sbd)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OeokoVC-WdWk","colab_type":"text"},"source":["<font color=green>While the function `split_on_newlines` can be named anything we want, it's important to use the name `sbd` for the SentenceSegmenter.</font>"]},{"cell_type":"code","metadata":{"id":"iWpYNa20WdWm","colab_type":"code","colab":{},"outputId":"d3e6ea5b-3b5d-4b8c-e72e-d4c34850a8c9"},"source":["doc = nlp(mystring)\n","for sent in doc.sents:\n","    print([token.text for token in sent])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['This', 'is', 'a', 'sentence', '.', 'This', 'is', 'another', '.', '\\n\\n']\n","['This', 'is', 'a', '\\n']\n","['third', 'sentence', '.']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"puzjmNPfWdWt","colab_type":"text"},"source":["<font color=green>Here we see that periods no longer affect segmentation, only linebreaks do. This would be appropriate when working with a long list of tweets, for instance.</font>\n","## Next Up: POS Assessment"]}]}